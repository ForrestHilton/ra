\documentclass[10pt,aspectratio=169]{beamer}

% All the boilerplate is in raslides.sty
% Note that this also pulls in a custom vogtwidebar.sty
\usepackage{raslides}

\author{Ji\v{r}\'i Lebl}

\institute[OSU]{%
Departemento pri Matematiko de Oklahoma {\^S}tata Universitato}

\title{BA: 2.5}

\date{}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}
\begin{definition}
Given a sequence $\{ x_n \}_{n=1}^\infty$, a \emph{series} is the formal object
\begin{equation*}
\sum_{n=1}^\infty x_n
%\qquad
%\text{or sometimes just}
%\qquad
%\sum x_n
\end{equation*}
\pause
A series \emph{converges} if the sequence $\{ s_k \}_{k=1}^\infty$ defined by
\begin{equation*}
s_k \coloneqq \sum_{n=1}^k x_n = x_1 + x_2 + \cdots + x_k 
\quad \text{converges}.
\end{equation*}
\pause
The numbers $s_k$ are called
\emph{partial sums}.
\pause
If the series converges, we write
\begin{equation*}
\sum_{n=1}^\infty x_n =  \lim_{k\to\infty} s_k 
\quad \text{(cheating a little by treating the series as a number)}.
\end{equation*}
\pause
If $\{ s_k \}_{k=1}^\infty$ diverges,
we say the series is \emph{divergent}.
\end{definition}

\end{frame}

\begin{frame}
If a series is convergent, then
\quad
$\displaystyle
\sum_{n=1}^\infty x_n
=
\lim_{k\to\infty} 
\sum_{n=1}^k x_n$.

\pause
\medskip

If the series does not converge, the right hand side is nonsense.

\pause
So (unlike for sequences) $\displaystyle\sum_{n=1}^\infty x_n$ means two different things:

\pause
1) notation for the series,

\pause
2) the actual limit.

\pause
\medskip

\textbf{Remark:}
We could start at a different index:
\quad
$\displaystyle
\sum_{n=0}^\infty r^n = \sum_{n=1}^\infty r^{n-1}$.

\pause
\medskip

\textbf{Remark:}
It is common (but we will not) to write $\displaystyle\sum_{n=1}^\infty x_n$ informally as
\begin{equation*}
x_1 + x_2 + x_3 + \cdots
\end{equation*}

\end{frame}

\begin{frame}

\textbf{Example:}
$\displaystyle \sum_{n=1}^\infty \frac{1}{2^n}$
converges and the limit is 1.  That is,
$\displaystyle
\sum_{n=1}^\infty \frac{1}{2^n} = 
\lim_{k\to\infty} \sum_{n=1}^k \frac{1}{2^n} = 
1$.

\pause
\medskip

\textbf{Proof:} By induction (exercise), \quad
$\displaystyle
\left( \sum_{n=1}^k \frac{1}{2^n} \right)
+ \frac{1}{2^k}
= 1$.

\pause
\medskip

\hspace*{\fill}
\subimport*{../figures/}{figcutseries.pdf_t}
\hspace*{\fill}

\pause
\medskip

Let $s_k$ be the partial sum, then
\quad
$\displaystyle
\abs{
1 - s_k 
}
=
\abs{
1 - 
\sum_{n=1}^k \frac{1}{2^n}
}
\pause
=
\abs{\frac{1}{2^k}} = 
\frac{1}{2^k}$.

\pause
\medskip

$\bigl\{ \frac{1}{2^k} \bigr\}_{k=1}^\infty = \bigl\{ \abs{1-s_k}
\bigr\}_{k=1}^\infty$
converges to $0$
\pause
\wthus $\{ s_k \}_{k=1}^\infty$ converges to 1.
\qed

\end{frame}

\begin{frame}

\begin{proposition}
Suppose
$-1 < r < 1$.  Then the \emph{geometric series}
$\displaystyle \sum_{n=0}^\infty r^n$ converges, and
%\begin{equation*}
\quad
$\displaystyle
\sum_{n=0}^\infty r^n = \frac{1}{1-r}
$.
%\end{equation*}
\end{proposition}

\pause

\textbf{Proof:} Exercise.

\pause
\medskip

One proves
\begin{equation*}
\sum_{n=0}^{k-1} r^n = \frac{1-r^k}{1-r} ,
\end{equation*}
\pause
and then one takes the limit $k \to \infty$.

\end{frame}

\begin{frame}

\begin{proposition}[tail of a series]
Let $\displaystyle\sum_{n=1}^\infty x_n$ be a series.  Let $M \in \N$.  Then
\begin{equation*}
\sum_{n=1}^\infty x_n \quad \text{converges if and only if} \quad
\sum_{n=M}^\infty x_n \quad \text{converges.}
\end{equation*}
\end{proposition}

\pause
\textbf{Proof:}
Consider partial sums of the two series (for $k \geq M$)
\begin{equation*}
\sum_{n=1}^{k} x_n
=
\left(
\sum_{n=1}^{M-1} x_n
\right)
+
\sum_{n=M}^{k} x_n .
\end{equation*}
\pause
Note that 
$\sum_{n=1}^{M-1} x_n$ is a fixed number.

\pause
\medskip

Adding a constant does not change the convergence of a sequence.
\qed

\end{frame}

\begin{frame}

\begin{definition}
$\displaystyle\sum_{n=1}^\infty x_n$ is \emph{Cauchy} (\emph{Cauchy series})
if the sequence of partial sums $\{ s_n \}_{n=1}^\infty$ is Cauchy.
\end{definition}

\pause
A sequence converges \wiffif it is Cauchy.
\pause \quad So:
A series converges \wiffif it is Cauchy.

\pause
\medskip

$\displaystyle\sum_{n=1}^\infty x_n$ is Cauchy if $\forall$ $\epsilon > 0$, $\exists$
$M \in \N$, s.\ t.\ $\forall$ $n,k \geq M$, ~
$\displaystyle
\abs{ \left( \sum_{i=1}^k x_i \right) - \left( \sum_{i=1}^n x_i \right) }
< \epsilon$.

\pause
\medskip

WLOG assume $n < k$.  Then
\quad
$\displaystyle
\abs{ \left( \sum_{i=1}^k x_i \right) - \left( \sum_{i=1}^n x_i \right) }
=
\abs{ \sum_{i={n+1}}^k x_i }
< \epsilon$.
\pause
\quad
\thus

\begin{proposition}
$\displaystyle\sum_{n=1}^\infty x_n$ is Cauchy ~if~ $\forall$ $\epsilon > 0$, 
$\exists$ $M \in \N$ such that $\forall$ $n \geq M$
and $\forall$ $k > n$, 
\quad
$\displaystyle \abs{ \sum_{i={n+1}}^k x_i } < \epsilon$.
\end{proposition}

\end{frame}

\begin{frame}

\begin{proposition}
Let $\displaystyle\sum_{n=1}^\infty x_n$ be a convergent series.  Then
$\{ x_n \}_{n=1}^\infty$ is convergent and
%\begin{equation*}
\quad
$\displaystyle
\lim_{n\to\infty} x_n = 0
$
.
%\end{equation*}
\end{proposition}

\pause
\textbf{Proof:}
$\displaystyle\sum_{n=1}^\infty x_n$ is convergent \wthus it is Cauchy.

\pause
\medskip

Let $\epsilon > 0$ be given.
%
\pause
%\medskip
\qquad
%
$\exists$ $M$ such that $\forall$ $n \geq M$, \quad
$\displaystyle
\epsilon > 
\abs{ \sum_{i={n+1}}^{n+1} x_i }
\pause
=
\abs{ x_{n+1} }$.

\pause
\medskip

\thus \quad for every $n \geq M+1$, we have $\abs{x_{n}} < \epsilon$.
\qed

\pause
\medskip

\textbf{Example:}
If $r \geq 1$ or $r \leq -1$, then the geometric series $\displaystyle \sum_{n=0}^\infty r^n$
diverges.

\pause
\medskip

\textbf{Proof:}
$\abs{r^n} = \abs{r}^n \geq 1^n = 1$ 
\pause
\wthus terms do not go to 0
\pause
\wthus
$\displaystyle\sum_{n=1}^\infty r^n$ diverges.
\qed

\end{frame}

\begin{frame}

\textbf{Example:}
The \emph{harmonic series} $\displaystyle\sum_{n=1}^\infty \frac{1}{n}$ diverges
(despite the fact that $\lim\limits_{n\to\infty} \frac{1}{n} = 0$).

\pause
\medskip

\textbf{Proof:}
Write the partial sums $s_n$ for $n = 2^k$ as:

\pause
\medskip

$s_1 = 1$, \quad
\pause
$s_2 = \left( 1 \right) + \left( \frac{1}{2} \right)$, \quad 
\pause
$s_4 = \left( 1 \right) + \left( \frac{1}{2} \right) +
        \left( \frac{1}{3} + \frac{1}{4} \right)$, \quad
\pause
%\medskip
$s_8 = \left( 1 \right) + \left( \frac{1}{2} \right) +
        \left( \frac{1}{3} + \frac{1}{4} \right) +
        \left( \frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{8}
\right)$,

\pause
\medskip

$\displaystyle s_{2^k} = 
1 + 
\sum_{i=1}^k
\left(
\sum_{m=2^{i-1}+1}^{2^i} \frac{1}{m}
\right)$.
%
\pause
%\medskip
\qquad
Note
~$\frac{1}{3} + \frac{1}{4} \geq \frac{1}{4} + \frac{1}{4}
\pause
=
\frac{1}{2}$~
\pause
and
~$\frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{8}
\geq \frac{1}{8} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8}
\pause
=
\frac{1}{2}$.

\pause
\medskip

%More generally
%\quad
$\displaystyle
\sum_{m=2^{k-1}+1}^{2^k} \frac{1}{m}
\geq
\sum_{m=2^{k-1}+1}^{2^k} \frac{1}{2^k}
\pause
=
(2^{k-1}) \frac{1}{2^k}
\pause
=
\frac{1}{2}$
%.
%
\pause
%\medskip
%
%\qquad
\hfill\thus\hfill
% \quad
$\displaystyle
s_{2^k} = 
1 + 
\sum_{i=1}^k
\left(
\sum_{m=2^{i-1}+1}^{2^i} \frac{1}{m}
\right) 
\pause
\geq
1 + \sum_{i=1}^k \frac{1}{2} = 1 + \frac{k}{2}$.

\pause
\medskip

$\{ \frac{k}{2} \}_{k=1}^\infty$ is unbounded
\pause
\wthus
$\{ s_{2^k} \}_{k=1}^\infty$ is unbounded
\pause
\wthus $\{ s_n \}_{n=1}^\infty$ is unbounded.

\medskip

So $\{ s_n \}_{n=1}^\infty$ diverges, that is,
$\displaystyle\sum_{n=1}^\infty \frac{1}{n}$ diverges.
\qed

\end{frame}

\begin{frame}

\begin{proposition}[Linearity of series]
Let $\alpha \in \R$ and $\displaystyle\sum_{n=1}^\infty x_n$ and
$\displaystyle\sum_{n=1}^\infty y_n$ be
convergent series.
\pause
Then
\begin{enumerate}[(i)]
\item
$\displaystyle\sum_{n=1}^\infty \alpha x_n$ converges and \quad
$\displaystyle
\sum_{n=1}^\infty \alpha x_n
=
\alpha \sum_{n=1}^\infty x_n$.
\item\pause
$\displaystyle\sum_{n=1}^\infty ( x_n + y_n )$ converges and \quad
$\displaystyle
\sum_{n=1}^\infty ( x_n + y_n ) 
=
\left( \sum_{n=1}^\infty x_n \right)
+
\left( \sum_{n=1}^\infty y_n \right)$.
\end{enumerate}
\end{proposition}

\pause
\textbf{Proof:}
(i)
The $k$th partial sum is 
~~
$\displaystyle
\sum_{n=1}^k \alpha x_n
=
\alpha \left( \sum_{n=1}^k x_n \right)$.

\pause
\medskip

Constant multiple of a convergent sequence is convergent.

\pause
\medskip

(ii) The $k$th partial sum is
~~
$\displaystyle
\sum_{n=1}^k ( x_n + y_n ) 
=
\left( \sum_{n=1}^k x_n \right)
+
\left( \sum_{n=1}^k y_n \right)$.

\pause
\medskip

Sum of convergent sequences converges to the sum of the limits.
\qed

\end{frame}

\begin{frame}

\textbf{Example:}
By the first item, if $\abs{r} < 1$ and $i \in \N$, then
\begin{equation*}
r^i \sum_{n=0}^\infty r^n =
\sum_{n=0}^\infty r^{n+i}
=
\sum_{n=i}^\infty r^n .
\end{equation*}
\pause
Hence,
\begin{equation*}
\sum_{n=i}^\infty r^n = \frac{r^i}{1-r} .
\end{equation*}

\pause
\medskip

\textbf{Remark:}
Multiplying series is not as simple as adding (see 2.6).

\pause
Obviously, we don't multiply term by term:
$(a+b)(c+d) \not= ac+bd$.

\end{frame}

\begin{frame}
Monotone sequences are easier than arbitrary sequences

\pause
\medskip

\thus \quad
$\displaystyle\sum_{n=1}^\infty x_n$ where $x_n \geq 0$ for all $n$ are easier,
as partial sums are monotone increasing.

\pause
\begin{proposition}
If $x_n \geq 0$ for all $n$, then $\displaystyle\sum_{n=1}^\infty x_n$ converges if and only if
the sequence of partial sums is bounded above.
\end{proposition}

\pause
The limit of a monotone increasing sequence is the supremum:

\pause
If
$x_n \geq 0$ for all $n$, then
\begin{equation*}
\sum_{n=1}^k x_n \leq
\sum_{n=1}^\infty x_n .
\end{equation*}
\pause
(still true if we allow infinite limits).

\end{frame}

\begin{frame}

\begin{definition}
$\displaystyle\sum_{n=1}^\infty x_n$
\emph{converges absolutely} if
$\displaystyle\sum_{n=1}^\infty \abs{x_n}$ converges.

\pause
If a series converges, but not absolutely,
it \emph{converges conditionally}.
\end{definition}

\pause
\begin{proposition}
If $\displaystyle\sum_{n=1}^\infty x_n$ converges absolutely, then it converges.
\end{proposition}

\pause
\textbf{Proof:}
If $\displaystyle\sum_{n=1}^\infty x_n$ converges absolutely, then
$\displaystyle\sum_{n=1}^\infty \abs{x_n}$ is convergent hence Cauchy.

\pause
\medskip

$\forall$ $\epsilon > 0$,
$\exists$ $M$ such that $\forall$ $k \geq M$ and all $n > k$,
\quad
$\displaystyle
\sum_{i=k+1}^n \abs{x_i} 
=
\abs{ \sum_{i=k+1}^n \abs{x_i} }
<
\epsilon$.

\pause
\medskip

By triangle inequality, %\quad
$\displaystyle
\abs{ \sum_{i=k+1}^n x_i }
\leq
\sum_{i=k+1}^n \abs{x_i}
\pause
<
\epsilon$
%
\pause
%\medskip
\wthus
$\displaystyle\sum_{n=1}^\infty x_n$ is Cauchy ~\thus~ converges.
\qed

\end{frame}

\begin{frame}

\textbf{Example:}
$\displaystyle
\sum_{n=1}^\infty \frac{{(-1)}^n}{n}$
\quad
converges (exercise),
\pause
but
\quad
$\displaystyle
\sum_{n=1}^\infty \frac{1}{n}$
\quad
diverges.

\pause
\medskip

So $\displaystyle\sum_{n=1}^\infty \frac{{(-1)}^n}{n}$ converges conditionally.

\pause
\medskip

If $\displaystyle\sum_{n=1}^\infty x_n$ converges absolutely, the limits of
$\displaystyle\sum_{n=1}^\infty x_n$ and
$\displaystyle\sum_{n=1}^\infty \abs{x_n}$ are in general different.

\pause
\medskip

However, (exercise)
\quad
$\displaystyle
\abs{ \sum_{i=1}^\infty x_i }
\leq
\sum_{i=1}^\infty \abs{x_i}$.

\pause
\medskip

Absolutely convergent series behave nicely (e.g., can be rearranged, or
multiplied, etc.). 

\pause
\medskip

Conditionally convergent series don't.
\end{frame}

\begin{frame}

\begin{proposition}[Comparison test]
Let $\displaystyle\sum_{n=1}^\infty x_n$ and $\displaystyle\sum_{n=1}^\infty y_n$ be series such that ~$0 \leq x_n \leq y_n$~
for all $n \in \N$.

\pause
(i)
%\begin{enumerate}[(i)]
%\item\pause
If $\displaystyle\sum_{n=1}^\infty y_n$ converges, then so does
$\displaystyle\sum_{n=1}^\infty x_n$.
\pause
\qquad
(ii)
%\item\pause
If $\displaystyle\sum_{n=1}^\infty x_n$ diverges, then so does
$\displaystyle\sum_{n=1}^\infty y_n$.
%\end{enumerate}
\end{proposition}

\pause
\textbf{Proof:}
Partial sums monotone (terms $\geq 0$) and
%Terms $\geq 0$ ~\thus~ partial sums monotone and
%increasing, and
\quad
\pause
$x_n \leq y_n$ for all $n$ ~\thus~
$\forall k$,
~%\quad
$\sum\limits_{n=1}^k x_n \leq \sum\limits_{n=1}^k y_n$.

\pause
(i) If $\sum\limits_{n=1}^\infty y_n$ converges, partial sums bounded
\wthus
$\exists B$ such that
$\forall k$,
\quad
$B \geq \sum\limits_{n=1}^k y_n
\pause
\geq
\sum\limits_{n=1}^k x_n$.

\pause
\medskip

Partial sums of $\sum\limits_{n=1}^\infty x_n$ are bounded ~\thus~
$\sum\limits_{n=1}^\infty x_n$ converges.

\pause
\medskip

(ii)
If $\sum\limits_{n=1}^\infty x_n$ diverges, partial sums unbounded
\pause
\wthus
$\forall B$ ~ $\exists k$ such that
\quad
$B \leq \sum\limits_{n=1}^k x_n
\pause
\leq \sum\limits_{n=1}^k y_n$.


\pause
\thus \quad partial sums of $\sum\limits_{n=1}^\infty y_n$ unbounded
\wthus $\sum\limits_{n=1}^\infty y_n$ diverges.
\qed

\end{frame}

\begin{frame}

\begin{proposition}[$p$-series or the $p$-test]
For $p \in \R$, 
\quad
$\displaystyle
\sum_{n=1}^\infty \frac{1}{n^p}$
\quad
converges if and only if $p > 1$.
\end{proposition}

\pause
\textbf{Proof:}
For $p \leq 1$, then
$\dfrac{1}{n^p} \geq \dfrac{1}{n}$. \quad
$\displaystyle\sum_{n=1}^\infty \frac{1}{n}$ diverges ~\thus~
$\displaystyle\sum_{n=1}^\infty \frac{1}{n^p}$ diverges (comparison).

\pause
\medskip

Suppose $p > 1$.  Let $s_n$ denote the $n$th partial sum (monotone seq.
again).

\pause
\medskip

$s_1 = 1$,
\pause
\quad
$s_3 = \left( 1 \right) + \left( \frac{1}{2^p} + \frac{1}{3^p} \right)$,
\pause
\quad
$s_7 = \left( 1 \right) + \left( \frac{1}{2^p} + \frac{1}{3^p} \right) +
        \left( \frac{1}{4^p} + \frac{1}{5^p} + \frac{1}{6^p} + \frac{1}{7^p}
\right)$,

\pause
$\displaystyle
 s_{2^k - 1} = 
1 + 
\sum_{i=1}^{k-1}
\left(
\sum_{m=2^i}^{2^{i+1}-1} \frac{1}{m^p}
\right)$.
%
\pause
\quad
%\medskip
%
Note %$2^p < 3^p$, so
$\frac{1}{2^p} + \frac{1}{3^p} <
\frac{1}{2^p} + \frac{1}{2^p}$
\pause
and
%Similarly,
$\frac{1}{4^p} + \frac{1}{5^p} +
\frac{1}{6^p} + \frac{1}{7^p} <
\frac{1}{4^p} + \frac{1}{4^p} +
\frac{1}{4^p} + \frac{1}{4^p}$.

\pause
\medskip

For all $k \geq 2$, 

%\quad
$\displaystyle
s_{2^k-1}
=
1+
\sum_{i=1}^{k-1}
\left(
\sum_{m=2^{i}}^{2^{i+1}-1} \frac{1}{m^p}
\right) 
\pause
<
1+
\sum_{i=1}^{k-1}
\left(
\sum_{m=2^{i}}^{2^{i+1}-1} \frac{1}{{(2^i)}^p}
\right) 
%$
%
\pause
%\medskip
%
%\qquad\qquad\qquad\qquad\qquad\qquad
%$\displaystyle
=
1+
\sum_{i=1}^{k-1}
\left(
\frac{2^i}{{(2^i)}^p}
\right) 
\pause
=
1+
\sum_{i=1}^{k-1}
{\left(
\frac{1}{2^{p-1}}
\right)}^i$.

\end{frame}

\begin{frame}
$p > 1$ \wthus $\frac{1}{2^{p-1}} < 1$.

\pause
\medskip

The geometric series
\quad
$\displaystyle
\sum_{i=1}^\infty
{\left(
\frac{1}{2^{p-1}}
\right)}^i$ \quad converges.

\pause
\medskip

\thus\quad
$\displaystyle
s_{2^k-1} < 
1+
\sum_{i=1}^{k-1}
{\left(
\frac{1}{2^{p-1}}
\right)}^i 
\pause
\leq 
1+
\sum_{i=1}^\infty
{\left(
\frac{1}{2^{p-1}}
\right)}^i$.

\pause
\medskip

For every $n$ there is a $k \geq 2$ such that $n \leq 2^k-1$

\pause
\medskip

\thus\qquad
$\displaystyle
s_n \leq s_{2^k-1}
\pause
< 
1+
\sum_{i=1}^\infty
{\left(
\frac{1}{2^{p-1}}
\right)}^i$.

\pause
\medskip

The sequence of partial sums is bounded
\pause
\wthus the series converges.
\qed

\end{frame}

\begin{frame}

\textbf{Example:}
$\displaystyle\sum_{n=1}^\infty \frac{1}{n^2+1}$ converges.

\pause
\medskip

\textbf{Proof:}  $\dfrac{1}{n^2+1} < \dfrac{1}{n^2}$ for all $n \in \N$.

\pause
\medskip

$\displaystyle\sum_{n=1}^\infty \frac{1}{n^2}$ converges by the $p$-series test.
%
\pause
%\medskip
\qquad
By the comparison test, $\displaystyle\sum_{n=1}^\infty \frac{1}{n^2+1}$ converges.
\qed

\pause
\medskip

Often easier to show a series converges than it is to find the limit.

\pause
E.g., easy to see
$\displaystyle\sum_{n=1}^\infty \frac{1}{n^2}$ converges,
%
\pause
much harder to show the limit is $\nicefrac{\pi^2}{6}$.

\pause
\medskip

\textbf{Remark:}
$\displaystyle \zeta(p) = \sum_{n=1}^\infty \frac{1}{n^p}$ is the
``Riemann zeta function''.

\pause
Understanding its roots is one of the most famous unsolved problems in
mathematics, with many applications.
\end{frame}

\begin{frame}
Suppose $r > 0$.
Ratio of two subsequent terms in the geometric series

$\displaystyle \sum_{n=0}^\infty r^n$ is $\dfrac{r^{n+1}}{r^n} = r$, and $\displaystyle\sum_{n=0}^\infty r^n$ converges
whenever $r < 1$.
%
\pause
%\medskip
%
We can generalize this.

\begin{proposition}[Ratio test]
Let $\displaystyle\sum_{n=1}^\infty x_n$ be a series, $x_n \not= 0$ for all $n$, and \quad
$L \coloneqq \lim\limits_{n\to\infty} \frac{\abs{x_{n+1}}}{\abs{x_n}}$ \quad exists.
%\begin{enumerate}[(i)]
%\item
%\pause

\pause
(i)
If $L < 1$, then $\displaystyle\sum_{n=1}^\infty x_n$ converges absolutely.
\qquad
\pause
(ii)
%\item
%\pause
If $L > 1$, then $\displaystyle\sum_{n=1}^\infty x_n$ diverges.
%\end{enumerate}
\end{proposition}

\pause
\textbf{Proof:}
If $L > 1$, by ratio test for seqs., $\{ x_n \}_{n=1}^\infty$ diverges ~\thus~
the series
%$\displaystyle\sum_{n=1}^\infty x_n$
cannot converge.

\pause
\medskip

Suppose $L < 1$ (clearly $L \geq 0$).
\quad
\pause
Pick $r$ such that $L < r < 1$.

\pause
\medskip

As $r-L > 0$, $\exists$ $M \in \N$ s.t. $\forall$ $n \geq M$,
\quad
$\abs{\frac{\abs{x_{n+1}}}{\abs{x_n}} - L} < r-L$
\wthus
$\frac{\abs{x_{n+1}}}{\abs{x_n}} < r$.

\pause
\medskip

For $n > M$ (that is for $n \geq M+1$),
write
\begin{equation*}
\abs{x_n} =
\abs{x_M}
\frac{\abs{x_{M+1}}}{\abs{x_{M}}}
\frac{\abs{x_{M+2}}}{\abs{x_{M+1}}}
\cdots
\frac{\abs{x_{n}}}{\abs{x_{n-1}}}
\pause
<
\abs{x_M}
r r \cdots r = \abs{x_M} r^{n-M}
\pause
= (\abs{x_M} r^{-M}) r^n .
\end{equation*}

\end{frame}

\begin{frame}
For $k > M$,
\quad
$\displaystyle
\sum_{n=1}^k \abs{x_n}
\pause
=
\left(\sum_{n=1}^{M} \abs{x_n} \right)
+
\left(\sum_{n=M+1}^{k} \abs{x_n} \right)
$

\pause
\medskip

\qquad\qquad\qquad\qquad\quad\,\!
$\displaystyle
<
\left(\sum_{n=1}^{M} \abs{x_n} \right)
+
\left(\sum_{n=M+1}^{k} 
(\abs{x_M} r^{-M}) r^n
\right)
%$
%
\pause
%\medskip
%
%\qquad\qquad\qquad\qquad\quad\,\!
%$\displaystyle
=
\left(\sum_{n=1}^{M} \abs{x_n} \right)
+
(\abs{x_M} r^{-M})
\left( \sum_{n=M+1}^{k} r^n \right)$.

\pause
\medskip

As $0 < r < 1$, ~~
$\displaystyle\sum_{n=0}^{\infty} r^n$ converges
\pause
\wthus
$\displaystyle\sum_{n=M+1}^{\infty} r^n$ converges.

\pause
\medskip

Take limit as $k \to \infty$.

\pause
\medskip

$\displaystyle
\sum_{n=1}^k \abs{x_n}
<
\left(\sum_{n=1}^{M} \abs{x_n} \right)
+
(\abs{x_M} r^{-M})
\left( \sum_{n=M+1}^{k} r^n \right) 
\pause
\leq
\left(\sum_{n=1}^{M} \abs{x_n} \right)
+
(\abs{x_M} r^{-M})
\left( \sum_{n=M+1}^{\infty} r^n \right)$.


\pause
\medskip

The RHS does not depend on $k$
\pause
\wthus
partial sums of $\displaystyle\sum_{n=1}^\infty \abs{x_n}$ are bounded

\pause
\thus \quad $\displaystyle\sum_{n=1}^\infty \abs{x_n}$ converges
\pause
\wthus
$\displaystyle\sum_{n=1}^\infty x_n$ converges absolutely.
\qed

\end{frame}

\begin{frame}

\textbf{Example:}
\begin{equation*}
\sum_{n=1}^\infty \frac{2^n}{n!}
\qquad
\text{converges absolutely.}
\end{equation*}

\pause
\medskip

\textbf{Proof:}
\begin{equation*}
\lim_{n\to\infty} \frac{2^{(n+1)}/(n+1)!}{2^n / n!} =
\lim_{n\to\infty} \frac{2}{n+1} = 0 .
\end{equation*}
\pause
Therefore, the series converges absolutely by the ratio test.
\qed

\end{frame}

\begin{frame}

If $\displaystyle \sum_{n=1}^\infty x_n$ converges, then $x_n \to 0$.  

\pause
\medskip

But $x_n \to 0$ is not enough to get the converse.
It has to go to zero fast enough

(let's stick with series with positive terms, it's
complicated if negative terms are involved).

\pause
\medskip

One can prove:

\medskip

\textbf{Exercise:}
Suppose $\{ x_n \}_{n=1}^\infty$ is a decreasing sequence and
$\displaystyle\sum_{n=1}^\infty x_n$ converges.

Prove $\displaystyle \lim_{n\to\infty} n x_n = 0$.

\pause
\medskip

Converse still doesn't hold:
$\displaystyle \sum_{n=2}^\infty \frac{1}{n \ln n}$ diverges
even though $\lim\limits_{n\to \infty} n \left( \dfrac{1}{n \ln n} \right) = 0$.

\end{frame}

\end{document}
